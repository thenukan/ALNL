# -*- coding: utf-8 -*-
"""ViT implementation

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YBdBUVfTL6C3RgDUJypDcN0iEWWUdOrw
"""

# ============================================================================
# Efficient Implementation: 5 Epochs, 40K Train, 10K Test
# ============================================================================

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import DataLoader, Subset
from torchvision import datasets, transforms
import timm
import random
import numpy as np
from sklearn.neighbors import NearestNeighbors
from sklearn.metrics import top_k_accuracy_score, precision_score, recall_score, f1_score
import time

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

# ============================================================================
# Efficient Configuration
# ============================================================================
class Config:
    # Dataset
    DATASET = 'CIFAR10'  # or 'CIFAR100'
    NUM_CLASSES = 10 if DATASET == 'CIFAR10' else 100
    NUM_TRAIN_SAMPLES = 40000  # 40K for training
    NUM_TEST_SAMPLES = 10000   # 10K for testing

    # Model - Use smaller models for efficiency
    MODEL_NAME = 'vit_tiny_patch16_224'
    FREEZE_BACKBONE = True  # Only train 0.1% of parameters
    USE_MIXED_PRECISION = True

    # Training - Only 5 epochs total
    EPOCHS_WARMUP = 2      # 1 epoch warmup
    EPOCHS_CLEAN = 4       # 2 epochs clean training
    EPOCHS_JOINT = 4       # 2 epochs joint training
    TOTAL_EPOCHS = 10

    # k-NN Clean Selection - Simplified
    KNN_K = 5              # Fewer neighbors for speed
    CLEAN_RATIO = 0.95     # Higher ratio to keep more samples

    # Patch Mixing - Reduced for efficiency
    MIX_PROBABILITY = 0.3  # Lower mixing rate
    PATCH_SIZE = (16, 16)
    ATTENTION_BLOCKS = 2   # Only use 2 blocks (faster)

    # Optimization
    BATCH_SIZE = 128       # Larger batches for efficiency
    LEARNING_RATE = 2e-3   # Higher LR for fast convergence
    WEIGHT_DECAY = 0.01
    AUX_WEIGHT = 0.3
    LABEL_SMOOTHING = 0.1

    # Misc
    NUM_WORKERS = 2
    SEED = 42

cfg = Config()
random.seed(cfg.SEED)
np.random.seed(cfg.SEED)
torch.manual_seed(cfg.SEED)

print(f"\n{'='*80}")
print(f"EFFICIENT CONFIGURATION: {cfg.DATASET}")
print(f"{'='*80}")
print(f"  Training samples: {cfg.NUM_TRAIN_SAMPLES:,}")
print(f"  Test samples: {cfg.NUM_TEST_SAMPLES:,}")
print(f"  Total epochs: {cfg.TOTAL_EPOCHS} (Fast training)")
print(f"  Batch size: {cfg.BATCH_SIZE} (Large batches)")
print(f"  Model: {cfg.MODEL_NAME} (Tiny for speed)")
print(f"  k-NN: k={cfg.KNN_K} (Fast selection)")
print(f"  Patch mixing: p={cfg.MIX_PROBABILITY} (Reduced)")
print(f"{'='*80}\n")

# ============================================================================
# Efficient Data Loading
# ============================================================================
# Simplified augmentation for speed
train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomCrop(224, padding=28),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

val_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

print(f"Loading {cfg.DATASET} dataset...")
if cfg.DATASET == 'CIFAR10':
    train_full = datasets.CIFAR10(root="./cifar10_data", train=True,
                                  download=True, transform=train_transform)
    test_full = datasets.CIFAR10(root="./cifar10_data", train=False,
                                 download=True, transform=val_transform)
else:
    train_full = datasets.CIFAR100(root="./cifar100_data", train=True,
                                   download=True, transform=train_transform)
    test_full = datasets.CIFAR100(root="./cifar100_data", train=False,
                                  download=True, transform=val_transform)

# Split: 40K train, 10K test (use all test data)
train_indices = list(range(cfg.NUM_TRAIN_SAMPLES))
test_indices = list(range(cfg.NUM_TEST_SAMPLES))

train_dataset = Subset(train_full, train_indices)
test_dataset = Subset(test_full, test_indices)

train_loader = DataLoader(
    train_dataset,
    batch_size=cfg.BATCH_SIZE,
    shuffle=True,
    num_workers=cfg.NUM_WORKERS,
    pin_memory=True,
    persistent_workers=True
)

test_loader = DataLoader(
    test_dataset,
    batch_size=cfg.BATCH_SIZE,
    shuffle=False,
    num_workers=cfg.NUM_WORKERS,
    pin_memory=True,
    persistent_workers=True
)

print(f"Dataset splits:")
print(f"  Train: {len(train_dataset):,} samples ({len(train_loader)} batches)")
print(f"  Test: {len(test_dataset):,} samples ({len(test_loader)} batches)")

# ============================================================================
# Efficient Model
# ============================================================================
class ViTDualHead(nn.Module):
    def __init__(self, model_name, num_classes, freeze_backbone=True):
        super().__init__()
        self.vit = timm.create_model(model_name, pretrained=True)

        if freeze_backbone:
            for param in self.vit.parameters():
                param.requires_grad = False

        self.vit.head = nn.Identity()
        feat_dim = self.vit.num_features

        # Simplified heads for efficiency
        self.fc_cls = nn.Sequential(
            nn.Dropout(0.1),
            nn.Linear(feat_dim, num_classes)
        )
        self.fc_aux = nn.Linear(feat_dim, 1)

        trainable = sum(p.numel() for p in self.parameters() if p.requires_grad)
        total = sum(p.numel() for p in self.parameters())
        print(f"\nModel: {model_name}")
        print(f"  Total params: {total:,}")
        print(f"  Trainable: {trainable:,} ({100*trainable/total:.2f}%)")

    def forward(self, x, return_features=False):
        features = self.vit(x)
        logits_main = self.fc_cls(features)
        logits_aux = self.fc_aux(features).squeeze(1)

        if return_features:
            return logits_main, logits_aux, features
        return logits_main, logits_aux

model = ViTDualHead(cfg.MODEL_NAME, cfg.NUM_CLASSES, cfg.FREEZE_BACKBONE).to(device)

# ============================================================================
# Fast k-NN Clean Selection (Cached)
# ============================================================================
@torch.no_grad()
def fast_select_clean_samples(model, loader, k=5, clean_ratio=0.95):
    """Fast k-NN selection with caching"""
    print(f"\nFast clean selection (k={k}, ratio={clean_ratio})...")
    start = time.time()

    model.eval()
    features_list = []
    labels_list = []

    # Extract features
    for images, labels in loader:
        images = images.to(device, non_blocking=True)
        _, _, features = model(images, return_features=True)
        features_list.append(features.cpu())
        labels_list.append(labels)

    features = torch.cat(features_list).numpy()
    labels = torch.cat(labels_list).numpy()

    # Fast k-NN
    knn = NearestNeighbors(n_neighbors=k+1, metric='cosine', n_jobs=-1)
    knn.fit(features)
    _, neighbors = knn.kneighbors(features)

    # Score: just use label agreement (faster)
    scores = []
    for i in range(len(features)):
        neighbor_labels = labels[neighbors[i][1:]]  # Exclude self
        agreement = (neighbor_labels == labels[i]).mean()
        scores.append(agreement)

    scores = np.array(scores)
    threshold = np.percentile(scores, (1 - clean_ratio) * 100)
    clean_indices = set(np.where(scores >= threshold)[0])

    print(f"  Selected {len(clean_indices):,}/{len(features):,} samples")
    print(f"  Time: {time.time()-start:.1f}s")
    return clean_indices

# ============================================================================
# Fast Attention Extraction
# ============================================================================
@torch.no_grad()
def fast_extract_attention(model, images):
    """Fast attention extraction using only 2 blocks"""
    model.eval()
    B = images.size(0)

    x = model.vit.patch_embed(images)
    cls_token = model.vit.cls_token.expand(B, -1, -1)
    x = torch.cat((cls_token, x), dim=1)
    x = model.vit.pos_drop(x + model.vit.pos_embed)

    # Only first 2 blocks
    for i in range(min(cfg.ATTENTION_BLOCKS, len(model.vit.blocks))):
        x = model.vit.blocks[i](x)

    patch_tokens = x[:, 1:]
    attention = patch_tokens.norm(dim=2)
    attention = F.softmax(attention, dim=1)

    return attention

# ============================================================================
# Fast Patch Mixing
# ============================================================================
def fast_patch_mixing(images, attention, mix_prob=0.3):
    """Efficient patch mixing"""
    B, C, H, W = images.shape
    mixed = images.clone()
    aux_labels = torch.zeros(B, dtype=torch.float32, device=images.device)

    n_patches_h = H // 16
    n_patches_w = W // 16
    num_mixed = 0

    for i in range(B):
        if random.random() < mix_prob and B > 1:
            j = random.choice([k for k in range(B) if k != i])

            # Sample patches
            attn_j = attention[j].cpu().numpy()
            patch_idx_j = np.random.choice(len(attn_j), p=attn_j)
            py_j, px_j = divmod(patch_idx_j, n_patches_w)

            attn_i = attention[i].cpu().numpy()
            patch_idx_i = np.random.choice(len(attn_i), p=attn_i)
            py_i, px_i = divmod(patch_idx_i, n_patches_w)

            # Swap patches
            y1_j, x1_j = py_j * 16, px_j * 16
            y1_i, x1_i = py_i * 16, px_i * 16

            mixed[i, :, y1_i:y1_i+16, x1_i:x1_i+16] = images[j, :, y1_j:y1_j+16, x1_j:x1_j+16]
            aux_labels[i] = 1.0
            num_mixed += 1

    return mixed, aux_labels, num_mixed

# ============================================================================
# Fast Training Loop
# ============================================================================
def train_epoch(model, loader, optimizer, scheduler, scaler, phase, clean_indices=None):
    model.train()
    total_loss = 0.0
    correct = 0
    total = 0
    num_mixed = 0

    criterion_cls = nn.CrossEntropyLoss(label_smoothing=cfg.LABEL_SMOOTHING)
    criterion_aux = nn.BCEWithLogitsLoss()

    for batch_idx, (images, labels) in enumerate(loader):
        images = images.to(device, non_blocking=True)
        labels = labels.to(device, non_blocking=True)

        # Filter clean samples in clean phase
        if phase == 'clean' and clean_indices is not None:
            global_indices = range(batch_idx * cfg.BATCH_SIZE,
                                  batch_idx * cfg.BATCH_SIZE + len(labels))
            clean_mask = torch.tensor([idx in clean_indices for idx in global_indices],
                                     device=device)
            if clean_mask.sum() == 0:
                continue
            images, labels = images[clean_mask], labels[clean_mask]

        # Patch mixing in joint phase
        if phase == 'joint':
            attention = fast_extract_attention(model, images)
            images, aux_labels, n_mix = fast_patch_mixing(images, attention, cfg.MIX_PROBABILITY)
            num_mixed += n_mix
        else:
            aux_labels = torch.zeros(len(images), dtype=torch.float32, device=images.device)

        # Forward
        with torch.amp.autocast('cuda'):
            logits_main, logits_aux = model(images)
            loss_cls = criterion_cls(logits_main, labels)
            loss_aux = criterion_aux(logits_aux, aux_labels)

            if phase == 'joint':
                loss = loss_cls + cfg.AUX_WEIGHT * loss_aux
            else:
                loss = loss_cls

        optimizer.zero_grad()
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()

        if scheduler:
            scheduler.step()

        total_loss += loss.item()
        _, pred = logits_main.max(1)
        correct += pred.eq(labels).sum().item()
        total += labels.size(0)

    avg_loss = total_loss / len(loader)
    accuracy = 100. * correct / total
    return avg_loss, accuracy, num_mixed

@torch.no_grad()
def evaluate(model, loader):
    model.eval()
    correct = 0
    total = 0

    for images, labels in loader:
        images = images.to(device, non_blocking=True)
        labels = labels.to(device, non_blocking=True)

        with torch.amp.autocast('cuda'):
            logits, _ = model(images)

        _, pred = logits.max(1)
        correct += pred.eq(labels).sum().item()
        total += labels.size(0)

    return 100. * correct / total

# ============================================================================
# Main Training
# ============================================================================
print(f"\n{'='*80}")
print(f"FAST TRAINING: 5 Epochs Only")
print(f"{'='*80}\n")

optimizer = optim.AdamW(
    filter(lambda p: p.requires_grad, model.parameters()),
    lr=cfg.LEARNING_RATE,
    weight_decay=cfg.WEIGHT_DECAY
)

scheduler = torch.optim.lr_scheduler.OneCycleLR(
    optimizer,
    max_lr=cfg.LEARNING_RATE,
    epochs=cfg.TOTAL_EPOCHS,
    steps_per_epoch=len(train_loader)
)

scaler = torch.amp.GradScaler('cuda')

best_acc = 0.0
clean_indices = None

for epoch in range(1, cfg.TOTAL_EPOCHS + 1):
    start_time = time.time()

    # Determine phase
    if epoch <= cfg.EPOCHS_WARMUP:
        phase = 'warmup'
        print(f"\nEpoch {epoch}/5 - WARMUP")
    elif epoch <= cfg.EPOCHS_WARMUP + cfg.EPOCHS_CLEAN:
        phase = 'clean'
        print(f"\nEpoch {epoch}/5 - CLEAN TRAINING")
        if epoch == cfg.EPOCHS_WARMUP + 1:
            clean_indices = fast_select_clean_samples(model, train_loader, cfg.KNN_K, cfg.CLEAN_RATIO)
    else:
        phase = 'joint'
        print(f"\nEpoch {epoch}/5 - JOINT (Patch Mixing)")

    # Train
    train_loss, train_acc, num_mixed = train_epoch(
        model, train_loader, optimizer, scheduler, scaler, phase, clean_indices
    )

    # Test
    test_acc = evaluate(model, test_loader)

    epoch_time = time.time() - start_time

    print(f"  Train: Loss={train_loss:.4f}, Acc={train_acc:.2f}%")
    if phase == 'joint':
        print(f"  Mixed: {num_mixed} patches")
    print(f"  Test: Acc={test_acc:.2f}%")
    print(f"  Time: {epoch_time:.1f}s")

    # Save best
    if test_acc > best_acc:
        best_acc = test_acc
        torch.save(model.state_dict(), f'./best_fast_model_{cfg.DATASET.lower()}.pth')
        print(f"  ✓ Best model saved!")

print(f"\n{'='*80}")
print(f"TRAINING COMPLETE!")
print(f"{'='*80}")
print(f"Best test accuracy: {best_acc:.2f}%")

# ============================================================================
# Detailed Test Evaluation
# ============================================================================
print(f"\nDetailed test evaluation...")
model.eval()
all_labels = []
all_logits = []

with torch.no_grad():
    for images, labels in test_loader:
        images = images.to(device, non_blocking=True)
        with torch.amp.autocast('cuda'):
            logits, _ = model(images)
        all_labels.extend(labels.numpy())
        all_logits.extend(logits.cpu().numpy())

all_labels = np.array(all_labels)
all_logits = np.array(all_logits)
all_preds = all_logits.argmax(axis=1)

top1 = (all_labels == all_preds).mean() * 100
top5 = top_k_accuracy_score(all_labels, all_logits, k=5) * 100
precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)
recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)
f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)

print(f"\n{'='*80}")
print(f"FINAL TEST RESULTS ({cfg.DATASET})")
print(f"{'='*80}")
print(f"  Top-1 Accuracy: {top1:.2f}%")
print(f"  Top-5 Accuracy: {top5:.2f}%")
print(f"  Precision: {precision:.4f}")
print(f"  Recall: {recall:.4f}")
print(f"  F1-Score: {f1:.4f}")
print(f"{'='*80}\n")

print(f"Model saved: ./best_fast_model_{cfg.DATASET.lower()}.pth")
print("Done!")

import matplotlib.pyplot as plt
import numpy as np

# =============================
# 1. Logged values from your run
# =============================

epochs = list(range(1, 11))

# Train loss and accuracy per epoch (from your log)
train_losses = [
    2.3295, 1.2136, 1.1043, 1.0926, 1.0898,
    1.0893, 1.2360, 1.2091, 1.1983, 1.1950
]
train_accs = [
    34.67, 71.08, 75.70, 76.09, 76.30,
    76.37, 78.83, 79.56, 80.25, 80.29
]

# Test accuracy per epoch
test_accs = [
    65.49, 76.89, 78.30, 78.03, 78.91,
    78.63, 78.62, 79.32, 79.41, 79.40
]

# Final test metrics
top1 = 79.40
top5 = 98.38
precision = 0.7972
recall    = 0.7940
f1        = 0.7928

# =============================
# 2. Loss and accuracy curves
# =============================

plt.figure(figsize=(15, 4))

# Training loss
plt.subplot(1, 3, 1)
plt.plot(epochs, train_losses, 'o-', color='tab:red', label='Train Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training Loss (CIFAR-10)')
plt.grid(True, alpha=0.3)
plt.legend()

# Training vs Test accuracy
plt.subplot(1, 3, 2)
plt.plot(epochs, train_accs, 'o-', color='tab:blue', label='Train Acc')
plt.plot(epochs, test_accs, 's--', color='tab:green', label='Test Acc')
plt.xlabel('Epoch')
plt.ylabel('Accuracy (%)')
plt.title('Accuracy per Epoch (CIFAR-10)')
plt.ylim(0, 100)
plt.grid(True, alpha=0.3)
plt.legend()

# Train–test gap
gap = [tr - te for tr, te in zip(train_accs, test_accs)]
plt.subplot(1, 3, 3)
plt.plot(epochs, gap, 'o-', color='tab:purple')
plt.axhline(0, color='black', linestyle='--', linewidth=1)
plt.xlabel('Epoch')
plt.ylabel('Train Acc - Test Acc (pp)')
plt.title('Generalization Gap')
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# =============================
# 3. Final test metrics bars
# =============================

plt.figure(figsize=(8, 4))

names = ['Top-1', 'Top-5', 'Precision', 'Recall', 'F1-score']
values = [top1, top5, precision * 100, recall * 100, f1 * 100]

colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FDCB6E', '#6C5CE7']
bars = plt.bar(names, values, color=colors, edgecolor='black')

plt.ylabel('Value (%)')
plt.title('Final CIFAR-10 Test Metrics')

for bar, val in zip(bars, values):
    h = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, h + 0.5,
             f'{val:.2f}', ha='center', va='bottom', fontsize=10)

plt.ylim(0, 100)
plt.grid(True, axis='y', alpha=0.3)
plt.tight_layout()
plt.show()

# ============================================================================
# Efficient Implementation: 5 Epochs, 40K Train, 10K Test (CIFAR-100)
# ============================================================================

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import DataLoader, Subset
from torchvision import datasets, transforms
import timm
import random
import numpy as np
from sklearn.neighbors import NearestNeighbors
from sklearn.metrics import top_k_accuracy_score, precision_score, recall_score, f1_score
import time

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

# ============================================================================
# Efficient Configuration
# ============================================================================
class Config:
    # Dataset
    DATASET = 'CIFAR100'          # CIFAR-100
    NUM_CLASSES = 100
    NUM_TRAIN_SAMPLES = 40000     # 40K for training
    NUM_TEST_SAMPLES = 10000      # 10K for testing

    # Model - slightly larger for 100 classes
    # If too slow, change back to 'vit_tiny_patch16_224'
    MODEL_NAME = 'vit_small_patch16_224'
    FREEZE_BACKBONE = True        # Only train small heads
    USE_MIXED_PRECISION = True

    # Training - Only 5 epochs total
    EPOCHS_WARMUP = 2             # 1 epoch warmup
    EPOCHS_CLEAN = 4              # 2 epochs clean training
    EPOCHS_JOINT = 4              # 2 epochs joint (patch mixing)
    TOTAL_EPOCHS = 10

    # k-NN Clean Selection - Simplified
    KNN_K = 5                     # Fewer neighbors for speed
    CLEAN_RATIO = 0.95            # Keep top 95% as "clean"

    # Patch Mixing - Reduced for efficiency
    MIX_PROBABILITY = 0.3         # Lower mixing rate
    PATCH_SIZE = (16, 16)
    ATTENTION_BLOCKS = 2          # Only use 2 blocks (faster)

    # Optimization
    BATCH_SIZE = 128              # Larger batches for efficiency
    LEARNING_RATE = 2e-3          # Higher LR for fast convergence
    WEIGHT_DECAY = 0.01
    AUX_WEIGHT = 0.3
    LABEL_SMOOTHING = 0.1

    # Misc
    NUM_WORKERS = 2
    SEED = 42

cfg = Config()
random.seed(cfg.SEED)
np.random.seed(cfg.SEED)
torch.manual_seed(cfg.SEED)

print(f"\n{'='*80}")
print(f"EFFICIENT CONFIGURATION: {cfg.DATASET}")
print(f"{'='*80}")
print(f"  Training samples: {cfg.NUM_TRAIN_SAMPLES:,}")
print(f"  Test samples: {cfg.NUM_TEST_SAMPLES:,}")
print(f"  Total epochs: {cfg.TOTAL_EPOCHS} (Fast training)")
print(f"  Batch size: {cfg.BATCH_SIZE} (Large batches)")
print(f"  Model: {cfg.MODEL_NAME} (Backbone frozen)")
print(f"  k-NN: k={cfg.KNN_K} (Fast selection)")
print(f"  Patch mixing: p={cfg.MIX_PROBABILITY} (Reduced)")
print(f"{'='*80}\n")

# ============================================================================
# Efficient Data Loading
# ============================================================================
train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomCrop(224, padding=28),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

val_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

print(f"Loading {cfg.DATASET} dataset...")
if cfg.DATASET == 'CIFAR10':
    train_full = datasets.CIFAR10(
        root="./cifar10_data", train=True,
        download=True, transform=train_transform
    )
    test_full = datasets.CIFAR10(
        root="./cifar10_data", train=False,
        download=True, transform=val_transform
    )
else:
    train_full = datasets.CIFAR100(
        root="./cifar100_data", train=True,
        download=True, transform=train_transform
    )
    test_full = datasets.CIFAR100(
        root="./cifar100_data", train=False,
        download=True, transform=val_transform
    )

# Use first 40K train, first 10K test
train_indices = list(range(cfg.NUM_TRAIN_SAMPLES))
test_indices = list(range(cfg.NUM_TEST_SAMPLES))

train_dataset = Subset(train_full, train_indices)
test_dataset = Subset(test_full, test_indices)

train_loader = DataLoader(
    train_dataset,
    batch_size=cfg.BATCH_SIZE,
    shuffle=True,
    num_workers=cfg.NUM_WORKERS,
    pin_memory=True,
    persistent_workers=True
)

test_loader = DataLoader(
    test_dataset,
    batch_size=cfg.BATCH_SIZE,
    shuffle=False,
    num_workers=cfg.NUM_WORKERS,
    pin_memory=True,
    persistent_workers=True
)

print("Dataset splits:")
print(f"  Train: {len(train_dataset):,} samples ({len(train_loader)} batches)")
print(f"  Test: {len(test_dataset):,} samples ({len(test_loader)} batches)")

# ============================================================================
# Efficient Model
# ============================================================================
class ViTDualHead(nn.Module):
    def __init__(self, model_name, num_classes, freeze_backbone=True):
        super().__init__()
        self.vit = timm.create_model(model_name, pretrained=True)

        if freeze_backbone:
            for p in self.vit.parameters():
                p.requires_grad = False

        # Replace classification head with identity
        self.vit.head = nn.Identity()
        feat_dim = self.vit.num_features

        # Simple heads
        self.fc_cls = nn.Sequential(
            nn.Dropout(0.1),
            nn.Linear(feat_dim, num_classes)
        )
        self.fc_aux = nn.Linear(feat_dim, 1)

        trainable = sum(p.numel() for p in self.parameters() if p.requires_grad)
        total = sum(p.numel() for p in self.parameters())
        print(f"\nModel: {model_name}")
        print(f"  Total params: {total:,}")
        print(f"  Trainable: {trainable:,} ({100.0 * trainable / total:.2f}%)")

    def forward(self, x, return_features=False):
        features = self.vit(x)
        logits_main = self.fc_cls(features)
        logits_aux = self.fc_aux(features).squeeze(1)
        if return_features:
            return logits_main, logits_aux, features
        return logits_main, logits_aux

model = ViTDualHead(cfg.MODEL_NAME, cfg.NUM_CLASSES, cfg.FREEZE_BACKBONE).to(device)

# ============================================================================
# Fast k-NN Clean Selection
# ============================================================================
@torch.no_grad()
def fast_select_clean_samples(model, loader, k=5, clean_ratio=0.95):
    print(f"\nFast clean selection (k={k}, ratio={clean_ratio})...")
    start = time.time()
    model.eval()

    features_list = []
    labels_list = []

    for images, labels in loader:
        images = images.to(device, non_blocking=True)
        logits_main, logits_aux, feats = model(images, return_features=True)
        features_list.append(feats.cpu())
        labels_list.append(labels)

    features = torch.cat(features_list, dim=0).numpy()
    labels = torch.cat(labels_list, dim=0).numpy()

    knn = NearestNeighbors(n_neighbors=k + 1, metric="cosine", n_jobs=-1)
    knn.fit(features)
    _, neighbors = knn.kneighbors(features)

    scores = []
    for i in range(len(features)):
        neighbor_labels = labels[neighbors[i][1:]]
        agreement = (neighbor_labels == labels[i]).mean()
        scores.append(agreement)

    scores = np.array(scores)
    threshold = np.percentile(scores, (1 - clean_ratio) * 100)
    clean_indices = set(np.where(scores >= threshold)[0])

    print(f"  Selected {len(clean_indices):,}/{len(features):,} samples")
    print(f"  Time: {time.time() - start:.1f}s")
    return clean_indices

# ============================================================================
# Fast Attention Extraction
# ============================================================================
@torch.no_grad()
def fast_extract_attention(model, images):
    model.eval()
    B = images.size(0)

    x = model.vit.patch_embed(images)
    cls_token = model.vit.cls_token.expand(B, -1, -1)
    x = torch.cat((cls_token, x), dim=1)
    x = model.vit.pos_drop(x + model.vit.pos_embed)

    for i in range(min(cfg.ATTENTION_BLOCKS, len(model.vit.blocks))):
        x = model.vit.blocks[i](x)

    patch_tokens = x[:, 1:]
    attention = patch_tokens.norm(dim=2)
    attention = F.softmax(attention, dim=1)
    return attention

# ============================================================================
# Fast Patch Mixing
# ============================================================================
def fast_patch_mixing(images, attention, mix_prob=0.3):
    B, C, H, W = images.shape
    mixed = images.clone()
    aux_labels = torch.zeros(B, dtype=torch.float32, device=images.device)

    n_patches_h = H // 16
    n_patches_w = W // 16
    num_mixed = 0

    for i in range(B):
        if random.random() < mix_prob and B > 1:
            j = random.choice([idx for idx in range(B) if idx != i])

            attn_j = attention[j].cpu().numpy()
            patch_idx_j = np.random.choice(len(attn_j), p=attn_j)
            py_j, px_j = divmod(patch_idx_j, n_patches_w)

            attn_i = attention[i].cpu().numpy()
            patch_idx_i = np.random.choice(len(attn_i), p=attn_i)
            py_i, px_i = divmod(patch_idx_i, n_patches_w)

            y1_j, x1_j = py_j * 16, px_j * 16
            y1_i, x1_i = py_i * 16, px_i * 16

            mixed[i, :, y1_i:y1_i + 16, x1_i:x1_i + 16] = \
                images[j, :, y1_j:y1_j + 16, x1_j:x1_j + 16]
            aux_labels[i] = 1.0
            num_mixed += 1

    return mixed, aux_labels, num_mixed

# ============================================================================
# Training and Evaluation
# ============================================================================
def train_epoch(model, loader, optimizer, scheduler, scaler, phase, clean_indices=None):
    model.train()
    total_loss = 0.0
    correct = 0
    total = 0
    num_mixed = 0

    criterion_cls = nn.CrossEntropyLoss(label_smoothing=cfg.LABEL_SMOOTHING)
    criterion_aux = nn.BCEWithLogitsLoss()

    for batch_idx, (images, labels) in enumerate(loader):
        images = images.to(device, non_blocking=True)
        labels = labels.to(device, non_blocking=True)

        # Clean phase: keep only clean indices
        if phase == "clean" and clean_indices is not None:
            global_indices = range(
                batch_idx * cfg.BATCH_SIZE,
                batch_idx * cfg.BATCH_SIZE + len(labels)
            )
            clean_mask = torch.tensor(
                [idx in clean_indices for idx in global_indices],
                device=device
            )
            if clean_mask.sum() == 0:
                continue
            images = images[clean_mask]
            labels = labels[clean_mask]

        # Joint phase: apply patch mixing
        if phase == "joint":
            attention = fast_extract_attention(model, images)
            images, aux_labels, n_mix = fast_patch_mixing(
                images, attention, cfg.MIX_PROBABILITY
            )
            num_mixed += n_mix
        else:
            aux_labels = torch.zeros(len(images), dtype=torch.float32, device=images.device)

        with torch.amp.autocast("cuda"):
            logits_main, logits_aux = model(images)
            loss_cls = criterion_cls(logits_main, labels)
            loss_aux = criterion_aux(logits_aux, aux_labels)
            loss = loss_cls if phase != "joint" else loss_cls + cfg.AUX_WEIGHT * loss_aux

        optimizer.zero_grad()
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()

        if scheduler is not None:
            scheduler.step()

        total_loss += loss.item()
        _, preds = logits_main.max(1)
        correct += preds.eq(labels).sum().item()
        total += labels.size(0)

    avg_loss = total_loss / len(loader)
    acc = 100.0 * correct / total if total > 0 else 0.0
    return avg_loss, acc, num_mixed

@torch.no_grad()
def evaluate(model, loader):
    model.eval()
    correct = 0
    total = 0

    for images, labels in loader:
        images = images.to(device, non_blocking=True)
        labels = labels.to(device, non_blocking=True)
        with torch.amp.autocast("cuda"):
            logits, _ = model(images)
        _, preds = logits.max(1)
        correct += preds.eq(labels).sum().item()
        total += labels.size(0)

    return 100.0 * correct / total if total > 0 else 0.0

# ============================================================================
# Main Training
# ============================================================================
print(f"\n{'='*80}")
print("FAST TRAINING: 5 Epochs Only (CIFAR-100)")
print(f"{'='*80}\n")

optimizer = optim.AdamW(
    filter(lambda p: p.requires_grad, model.parameters()),
    lr=cfg.LEARNING_RATE,
    weight_decay=cfg.WEIGHT_DECAY
)

scheduler = torch.optim.lr_scheduler.OneCycleLR(
    optimizer,
    max_lr=cfg.LEARNING_RATE,
    epochs=cfg.TOTAL_EPOCHS,
    steps_per_epoch=len(train_loader)
)

scaler = torch.amp.GradScaler("cuda")

best_acc = 0.0
clean_indices = None

for epoch in range(1, cfg.TOTAL_EPOCHS + 1):
    start_time = time.time()

    if epoch <= cfg.EPOCHS_WARMUP:
        phase = "warmup"
        print(f"\nEpoch {epoch}/{cfg.TOTAL_EPOCHS} - WARMUP")
    elif epoch <= cfg.EPOCHS_WARMUP + cfg.EPOCHS_CLEAN:
        phase = "clean"
        print(f"\nEpoch {epoch}/{cfg.TOTAL_EPOCHS} - CLEAN TRAINING")
        if epoch == cfg.EPOCHS_WARMUP + 1:
            clean_indices = fast_select_clean_samples(
                model, train_loader, cfg.KNN_K, cfg.CLEAN_RATIO
            )
    else:
        phase = "joint"
        print(f"\nEpoch {epoch}/{cfg.TOTAL_EPOCHS} - JOINT (Patch Mixing)")

    train_loss, train_acc, num_mixed = train_epoch(
        model, train_loader, optimizer, scheduler, scaler, phase, clean_indices
    )

    test_acc = evaluate(model, test_loader)
    epoch_time = time.time() - start_time

    print(f"  Train: Loss={train_loss:.4f}, Acc={train_acc:.2f}%")
    if phase == "joint":
        print(f"  Mixed: {num_mixed} images")
    print(f"  Test: Acc={test_acc:.2f}%")
    print(f"  Time: {epoch_time:.1f}s")

    if test_acc > best_acc:
        best_acc = test_acc
        torch.save(model.state_dict(), "./best_fast_model_cifar100.pth")
        print("  ✓ Best model saved!")

print(f"\n{'='*80}")
print("TRAINING COMPLETE!")
print(f"{'='*80}")
print(f"Best test accuracy: {best_acc:.2f}%")

# ============================================================================
# Detailed Test Evaluation
# ============================================================================
print("\nDetailed test evaluation...")
model.eval()
all_labels = []
all_logits = []

with torch.no_grad():
    for images, labels in test_loader:
        images = images.to(device, non_blocking=True)
        with torch.amp.autocast("cuda"):
            logits, _ = model(images)
        all_labels.extend(labels.numpy())
        all_logits.extend(logits.cpu().numpy())

all_labels = np.array(all_labels)
all_logits = np.array(all_logits)
all_preds = all_logits.argmax(axis=1)

top1 = (all_labels == all_preds).mean() * 100.0
top5 = top_k_accuracy_score(all_labels, all_logits, k=5) * 100.0
precision = precision_score(all_labels, all_preds, average="macro", zero_division=0)
recall = recall_score(all_labels, all_preds, average="macro", zero_division=0)
f1 = f1_score(all_labels, all_preds, average="macro", zero_division=0)

print(f"\n{'='*80}")
print("FINAL TEST RESULTS (CIFAR-100)")
print(f"{'='*80}")
print(f"  Top-1 Accuracy: {top1:.2f}%")
print(f"  Top-5 Accuracy: {top5:.2f}%")
print(f"  Precision: {precision:.4f}")
print(f"  Recall:    {recall:.4f}")
print(f"  F1-Score:  {f1:.4f}")
print(f"{'='*80}\n")

print("Model saved: ./best_fast_model_cifar100.pth")
print("Done!")

import matplotlib.pyplot as plt
import numpy as np

# =============================
# 1. Logged values from CIFAR-100 run (10 epochs)
# =============================

epochs = list(range(1, 11))

train_losses = [
    3.4866, 1.7209, 1.6025, 1.5664, 1.5369,
    1.5012, 1.5856, 1.5388, 1.5055, 1.4881
]

train_accs = [
    31.29, 72.58, 76.65, 77.93, 79.00,
    79.88, 83.27, 84.85, 86.03, 86.80
]

test_accs = [
    66.58, 74.02, 75.33, 75.60, 76.32,
    77.07, 77.58, 78.08, 78.42, 78.55
]

# Final test metrics
top1 = 78.55
top5 = 94.64
precision = 0.7895
recall    = 0.7855
f1        = 0.7854

# =============================
# 2. Loss and accuracy curves
# =============================

plt.figure(figsize=(15, 4))

# Training loss
plt.subplot(1, 3, 1)
plt.plot(epochs, train_losses, 'o-', color='tab:red', label='Train Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training Loss (CIFAR-100)')
plt.grid(True, alpha=0.3)
plt.legend()

# Training vs Test accuracy
plt.subplot(1, 3, 2)
plt.plot(epochs, train_accs, 'o-', color='tab:blue', label='Train Acc')
plt.plot(epochs, test_accs, 's--', color='tab:green', label='Test Acc')
plt.xlabel('Epoch')
plt.ylabel('Accuracy (%)')
plt.title('Accuracy per Epoch (CIFAR-100)')
plt.ylim(0, 100)
plt.grid(True, alpha=0.3)
plt.legend()

# Train–test gap
gap = [tr - te for tr, te in zip(train_accs, test_accs)]
plt.subplot(1, 3, 3)
plt.plot(epochs, gap, 'o-', color='tab:purple')
plt.axhline(0, color='black', linestyle='--', linewidth=1)
plt.xlabel('Epoch')
plt.ylabel('Train Acc - Test Acc (pp)')
plt.title('Generalization Gap')
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# =============================
# 3. Final test metrics bars
# =============================

plt.figure(figsize=(8, 4))

names = ['Top-1', 'Top-5', 'Precision', 'Recall', 'F1-score']
values = [top1, top5, precision * 100, recall * 100, f1 * 100]

colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FDCB6E', '#6C5CE7']
bars = plt.bar(names, values, color=colors, edgecolor='black')

plt.ylabel('Value (%)')
plt.title('Final CIFAR-100 Test Metrics')

for bar, val in zip(bars, values):
    h = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, h + 0.5,
             f'{val:.2f}', ha='center', va='bottom', fontsize=10)

plt.ylim(0, 100)
plt.grid(True, axis='y', alpha=0.3)
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import numpy as np

# CIFAR-10 metrics
c10_top1 = 79.40
c10_top5 = 98.38
c10_precision = 0.7972
c10_recall    = 0.7940
c10_f1        = 0.7928

# CIFAR-100 metrics
c100_top1 = 78.55
c100_top5 = 94.64
c100_precision = 0.7895
c100_recall    = 0.7855
c100_f1        = 0.7854

names = ['Top-1', 'Top-5', 'Precision', 'Recall', 'F1-score']
x = np.arange(len(names))

c10_values = [c10_top1, c10_top5, c10_precision * 100, c10_recall * 100, c10_f1 * 100]
c100_values = [c100_top1, c100_top5, c100_precision * 100, c100_recall * 100, c100_f1 * 100]

plt.figure(figsize=(8, 4))

plt.plot(x, c10_values, '-o', color='tab:blue', label='CIFAR-10')
plt.plot(x, c100_values, '-s', color='tab:orange', label='CIFAR-100')

plt.xticks(x, names)
plt.ylabel('Value (%)')
plt.title('Final Test Metrics: CIFAR-10 vs CIFAR-100')
plt.ylim(0, 100)
plt.grid(True, axis='y', alpha=0.3)
plt.legend()
plt.tight_layout()
plt.show()